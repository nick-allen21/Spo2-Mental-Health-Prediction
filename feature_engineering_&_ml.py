# -*- coding: utf-8 -*-
"""Feature Engineering & ML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jgEFCfIMU1WjjPe9UqjRGmvKdXtgAPkn

# Introduction

This notebook will begin to map the SpO2 data to mental health outcomes in the search for an objective measure for quantifying mental health.

# 1) Effective Package/Data loading
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import datetime
import pyarrow.parquet as pq
import numpy as np
import matplotlib.pyplot as plt
import random
from tabulate import tabulate
from google.colab import auth
from google.cloud import storage
from scipy import stats
import csv
import matplotlib.pyplot as plt
import pandas as pd
import subprocess
import datetime
from datetime import datetime, timedelta
import numpy as np
from collections import defaultdict
import seaborn as sns
import sys
import random
import logging
import os
import re
from dateutil.parser import parse
import time
import multiprocessing
from pathlib import Path
from matplotlib.animation import FuncAnimation
import matplotlib.pyplot as plt
from IPython.display import HTML
from moviepy.editor import ImageSequenceClip
from google.colab import drive
drive.mount('/content/drive')
plt.style.use("seaborn")

Spo2_path = "Path to you Spo2 Data, Global De-identified rows, Date columns"
check_point_path = "Path to checkpoints "
mental_health_path = "Path to mental health data"
df = pd.read_parquet(Spo2_path)
cpdf = pd.read_csv(check_point_path)
mhdf = pd.read_csv(mental_health_path)

"""# 2) Reformation of Data Frames

Making the data frame into one more cohesive data frame that is easier to work with for the purpose of my data

Using the df, cpdf, and mhdf into to make one cohesive data frame with the following structure

ID | % Of All Data | % of data (30 or 7) days before Ci | Date survey | 30 day average before checkpoint i|

We will create a dictionary
```
data = {
    'Global_Deidentified': []
    '% Of All Data Present': []
    'Num Surveys Done / 6': []
    'Date Survey i': []
    '% Data present in 30 days before Ci' = []
    '30 day average before survey Ci': []
    '7 day average before survey Ci': []
    'PSS Score at Ci': []
}
This framing is nice because it will allow us to keep adding columns of data in the previous days as we add new mental health features

```
And convert into Data frame. We will also have a dictionary of multiple data frames. The keys will be indivdual participants in our study. The values will be data frames.



```
data = {
    'Global_Deidentified' : data_frame
}

data_frame = {
  dates = []
  c1 = []
  c2 = []
  c3 = []
  c4 = []
  c5 = []
  c6 = []
}

```
data_frame : dates|c1|c2|c3|c4|c5|c6

where we have the 30 days of data leading up to each checkpoint.


"""

from datetime import timedelta
import pandas as pd

# Assuming df and cpdf are defined earlier in your code
start_date = pd.to_datetime("2022-11-14")
pre_checkpoint_month = {}

# Loop through rows in df
for index, row in df.iterrows():
    identifier = row['Global_Deidentified']
    # Initialize DataFrame for each identifier
    data_frame = pd.DataFrame()

    checkpoint_dates = {}
    for i in range(1, 7):
        column_head = f"c{i}"
        # Get the survey date for the current checkpoint
        Date_survey = pd.to_datetime(cpdf.loc[cpdf["Global_Deidentified"] == identifier, f"Date Taken c{i}"].iloc[0])

        # Check for NaN in Date_survey
        if pd.isna(Date_survey):
            continue

        # Calculate start date for data collection
        Date_time_before = max(Date_survey - timedelta(days=30), start_date)

        # Format date times as strings for column search
        Date_survey_str = Date_survey.strftime('%Y-%m-%d')
        Date_time_before_str = Date_time_before.strftime('%Y-%m-%d')

        # Add to checkpoint dates tuples list
        # Do this range and too list to start data analysis
        checkpoint_dates[column_head] = (Date_time_before_str, Date_survey_str)

        # Locate the column indices for the date range
        date_loc1 = df.columns.get_loc(Date_time_before_str)
        date_loc2 = df.columns.get_loc(Date_survey_str) + 1  # +1 to include the survey date

        # Extract data for the date range
        data = row[df.columns[date_loc1:date_loc2]].tolist()
        dates = df.columns[date_loc1:date_loc2].tolist()

        # Add to DataFrame
        temp_df = pd.DataFrame({'dates': dates, column_head: data})
        data_frame = pd.merge(data_frame, temp_df, on='dates', how='outer') if not data_frame.empty else temp_df

    # Add the DataFrame to the dictionary
    pre_checkpoint_month[identifier] = data_frame
    pre_checkpoint_month[identifier + 'c_dates'] = checkpoint_dates

import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def weighted_difference(data_7, data_average):
    difference = 0
    n = len(data_7)

    for i in range(n):
        data = data_7[i]
        # Linearly rising input to the sigmoid function from -6 to 6
        sigmoid_input = 12 * (i / (n - 1)) - 6
        weight = sigmoid(sigmoid_input)
        difference += weight * abs(data - data_average)

    return difference/n

# Example usage
data_7 = [1, 2, 3, 4, 5, 6, 7]  # Example data
data_average = np.mean(data_7)
result = weighted_difference(data_7, data_average)
print(result)

import pandas as pd
'''
data = {
    'Global_Deidentified': []
    '% Of All Data Present': []
    'Num Surveys Done / 6': []
    'Date Survey i': []
    '% Data present in 30 days before Ci' = []
    '30 day average before survey Ci': []
    '7 day average before survey Ci': []
    'PSS Score at Ci': []
}

Will convert dicionary of this structure to data frame
'''
# Total difference and weight the days right before the highest
# np.arragne(-3,3,1) with sigmoid based on range and weight the differences
# before a survey the highest

keys = ['Global_Deidentified', '% All Data', 'frac surveys',]
for i in range(1,7):
  keys.append(f'Date Taken c{i}')
  keys.append(f'% Present 30 before Date c{i}')
  keys.append(f'30 day average pre c{i}')
  keys.append(f'7 day average pre c{i}')
  keys.append(f'7 max - min pre c{i}')
  keys.append(f'days increasing pre c{i}')
  keys.append(f'30 max - min pre c{i}')
  #keys.append(f'15 max - min pre c{i}')
  keys.append(f'3 max - min pre c{i}')
  keys.append(f'ratio above below 30 c{i}')
  keys.append(f'ratio above below 7 c{i}')
  keys.append(f'3 day average pre c{i}')
  keys.append(f'9 day average pre c{i}')
  keys.append(f'days decreasing pre c{i}')
  keys.append(f'avg Difference 7 days pre c{i}')
  keys.append(f'Day before c{i}')
  keys.append(f'PSS Score at c{i}')
  keys.append(f'avg Difference 3 days pre c{i}')



data_dict = {key : [] for key in keys}


for idx, row in df.iterrows():

  Identifier = row['Global_Deidentified']
  data_dict['Global_Deidentified'].append(Identifier)
  data_dict['% All Data'].append((row.count() / len(row)) * 100)
  # Finding row index with the proper global identifier
  cp_row = cpdf[cpdf['Global_Deidentified'] == Identifier].iloc[0, 2:]
  data_dict['frac surveys'].append((cp_row.count() / (len(cp_row))) * 100)

  # All all of the survey dates
  for i in range(1, 7):

    # Add all of the survey dates
    Date_taken_key = f'Date Taken c{i}'
    data_dict[Date_taken_key].append(cp_row[Date_taken_key])

    # Add the percentage of data present before the survey
    # Acess the range of dates that we want from pre_checkpoint_month dictionary
    Date_range_key = Identifier + 'c_dates'
    Date_range_dict = pre_checkpoint_month[Date_range_key]
    if f'c{i}' in Date_range_dict.keys():
      # Get the tuple with the date ranges we want
      Date_range_tuple = Date_range_dict[f'c{i}']

      # List out all of the values between the dates that we want
      data_list = row[Date_range_tuple[0]:Date_range_tuple[1]].tolist()

      # Calculate percent of non-nan values
      non_nan_count = np.count_nonzero(~np.isnan(data_list))
      percentage_non_nan = (non_nan_count / len(data_list)) * 100
      data_dict[f'% Present 30 before Date c{i}'].append(percentage_non_nan)

      # Drop non-nan values and take the average
      # These are either 30 day averages, or averages until the start of the study
      data_average = row[Date_range_tuple[0]:Date_range_tuple[1]].dropna().mean()
      data_dict[f'30 day average pre c{i}'].append(data_average)

      # Add the 7 day average prior to a checkpoint
      index1 = df.columns.get_loc(Date_range_tuple[1])
      index0 = index1 - 7
      data_7_average = row.iloc[index0 : index1].dropna().mean()
      data_dict[f'7 day average pre c{i}'].append(data_7_average)

      above = sum(data >= data_average for data in data_list)
      below = sum(data < data_average for data in data_list)

      if below:
        data_dict[f'ratio above below 30 c{i}'].append(above/below)
      else:
        data_dict[f'ratio above below 30 c{i}'].append(np.nan)

      # Add the 7 day average prior to a checkpoint
      index1 = df.columns.get_loc(Date_range_tuple[1])
      index0 = index1 - 7
      data_7 = row.iloc[index0 : index1].dropna()
      if len(data_7) > 1:
        val = max(data_7) - min(data_7)
        data_dict[f'7 max - min pre c{i}'].append(val)
        data_dict[f'avg Difference 7 days pre c{i}'].append(weighted_difference(data_7, data_average))

      else:
        data_dict[f'7 max - min pre c{i}'].append(np.nan)
        data_dict[f'avg Difference 7 days pre c{i}'].append(np.nan)

      below_7 = sum(data < data_average for data in data_7)
      above_7 = sum(data >= data_average for data in data_7)
      if below_7:
        data_dict[f'ratio above below 7 c{i}'].append(above_7/below_7)
      else:
        data_dict[f'ratio above below 7 c{i}'].append(np.nan)

      index1 = df.columns.get_loc(Date_range_tuple[1])
      index0 = index1 - 3
      data_3 = row.iloc[index0 : index1].dropna()
      if len(data_3) > 1:
        val = max(data_3) - min(data_3)
        data_dict[f'3 max - min pre c{i}'].append(val)
        data_dict[f'avg Difference 3 days pre c{i}'].append(weighted_difference(data_7, data_average))
      else:
        data_dict[f'3 max - min pre c{i}'].append(np.nan)
        data_dict[f'avg Difference 3 days pre c{i}'].append(np.nan)

      pre_check_data = row.iloc[1:index1].dropna()
      count = 0
      prev = 0
      for val in reversed(pre_check_data):
        if val >= prev:
          count +=1
          prev = val
        else : break
      data_dict[f'days increasing pre c{i}'].append(count)

      count = 0
      prev = 100
      for val in reversed(pre_check_data):
        if val <= prev:
          count +=1
          prev = val
        else : break
      data_dict[f'days decreasing pre c{i}'].append(count)

      # Add the 7 day average prior to a checkpoint
      data_30 = data_average = row[Date_range_tuple[0]:Date_range_tuple[1]].dropna()
      if not data_30.empty:
        val = max(data_30) - min(data_30)
        data_dict[f'30 max - min pre c{i}'].append(val)
      else:
        data_dict[f'30 max - min pre c{i}'].append(np.nan)

      # Add the 7 day average prior to a checkpoint
      index1 = df.columns.get_loc(Date_range_tuple[1])
      index0 = index1 - 3
      data_3_average = row.iloc[index0 : index1].dropna().mean()
      data_dict[f'3 day average pre c{i}'].append(data_3_average)

      # Add the 7 day average prior to a checkpoint
      index1 = df.columns.get_loc(Date_range_tuple[1])
      index0 = index1 - 9
      data_9_average = row.iloc[index0 : index1].dropna().mean()
      data_dict[f'9 day average pre c{i}'].append(data_9_average)

      # Add the 7 day average prior to a checkpoint
      index1 = df.columns.get_loc(Date_range_tuple[1])
      index0 = index1 - 1
      data_1_average = row.iloc[index0 : index1].dropna().mean()
      data_dict[f'Day before c{i}'].append(data_1_average)

      # Add the PSS Score
      PSS_key = f'PSS_c{i}'
      mh_row = mhdf[mhdf['Global_Deidentified'] == Identifier].iloc[0]
      data_dict[f'PSS Score at c{i}'].append(mh_row[PSS_key])
    else:
      data_dict[f'avg Difference 3 days pre c{i}'].append(np.nan)
      data_dict[f'avg Difference 7 days pre c{i}'].append(np.nan)
      data_dict[f'days decreasing pre c{i}'].append(np.nan)
      data_dict[f'days increasing pre c{i}'].append(np.nan)
      data_dict[f'ratio above below 7 c{i}'].append(np.nan)
      data_dict[f'ratio above below 30 c{i}'].append(np.nan)
      data_dict[f'3 max - min pre c{i}'].append(np.nan)
      data_dict[f'30 max - min pre c{i}'].append(np.nan)
      data_dict[f'7 max - min pre c{i}'].append(np.nan)
      data_dict[f'Day before c{i}'].append(np.nan)
      data_dict[f'9 day average pre c{i}'].append(np.nan)
      data_dict[f'3 day average pre c{i}'].append(np.nan)
      data_dict[f'% Present 30 before Date c{i}'].append(np.nan)
      data_dict[f'30 day average pre c{i}'].append(np.nan)
      data_dict[f'7 day average pre c{i}'].append(np.nan)
      data_dict[f'PSS Score at c{i}'].append(np.nan)

df_omnis = pd.DataFrame(data_dict)
df_omnis = df_omnis.sort_values(by = '% All Data', ascending = False)
print(tabulate(df_omnis, headers='keys', tablefmt='psql', showindex = False))
for col in df_omnis.columns:
  print(col)

PSS_hist = []

for i in range(1, 7):
    non_null_values = df_omnis[f'PSS Score at c{i}'][df_omnis[f'PSS Score at c{i}'].notnull()].tolist()
    PSS_hist.extend(non_null_values)  # Using extend to add all items from the list

print(PSS_hist)
low_cutoff = np.percentile(PSS_hist, 30)
medium_cutoff = np.percentile(PSS_hist, 75)
Median = np.percentile(PSS_hist, 50)

print(low_cutoff)
print(medium_cutoff)
print("Median : ", Median)

plt.figure(figsize=(10, 6))  # Set the size of the plot
plt.hist(PSS_hist, bins=40, color='blue', alpha=0.7, rwidth=0.85)
plt.title('Histogram of PSS Values')  # Add a title
plt.xlabel('PSS Score')  # Label on X axis
plt.ylabel('Frequency')  # Label on Y axis
plt.xticks(np.arange(0, 41, 2))

# Show the plot
plt.grid(True)
plt.show()

# Let's update the code to use the actual column headings and titles from the provided DataFrame screenshot.
# As before, we will use the hypothetical data structure as the actual DataFrame is not provided.

# We'll create a function that can be used to generate the plots from the DataFrame `df_omnis`.
'''
changing to poppulate with k-means clustering derived centers

5.60588235
13.12735849
20.33793103

ziv values :

low = 7
mid = 20
high = 33

'''
def generate_stress_plots(df):
    # Define the stress level categories based on the PSS Score ranges
    stress_levels = {
        'Low Stress': (0, 13),
        #'Medium Stress': (10.299999999999955, 20.0),
        'High Stress': (13, 40)
    }

    # Function to categorize stress levels based on PSS Score
    def categorize_stress(row):
        for level, (low, high) in stress_levels.items():
            if low <= row <= high:
                return level
        #return 'Unknown'

    # Categorize stress for each PSS Score column and calculate the average 30 day pre c{i} for each category
    results = {}
    for column in df.columns:
        if column.startswith('PSS Score at '):
            stress_column = 'Stress Level ' + column.split(' ')[-1]
            df[stress_column] = df[column].apply(categorize_stress)

            # Calculating average for 30 day average pre column corresponding to the PSS Score column
            avg_column = '30 day average pre ' + column.split(' ')[-1]
            if avg_column in df.columns:
                results[avg_column] = df.groupby(stress_column)[avg_column].mean()

# Call the function with hypothetical data
generate_stress_plots(df_omnis)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_stress_levels(pre_checkpoint_month, df_omnis, days_to_output=7, total_data_threshold=40, pre_survey_threshold=50):
    # Initialize lists to hold the specified number of day values for high and low stress groups
    high_days = []
    low_days = []

    # Print the dates column for verification
    print(pre_checkpoint_month['DTUW'])

    # Iterate through each row in df_omnis
    for idx, row in df_omnis.iterrows():
        identifier = row['Global_Deidentified']
        df = pre_checkpoint_month[identifier]
        date_dict = pre_checkpoint_month[identifier + 'c_dates']
        total_present = row['% All Data']

        if total_present > total_data_threshold:  # Check if the participant has more than the specified percentage of their total data present
            for i in range(1, 7):  # Loop through c1 to c6
                innerkey = f'c{i}'
                stressKey = 'Stress Level' + f' c{i}'
                stressState = row[stressKey]
                present_pre_survey = row['% Present 30 before Date ' + innerkey]

                # Check if innerkey exists in date_dict and present_pre_survey is more than the specified threshold
                if innerkey in date_dict and present_pre_survey > pre_survey_threshold:
                    # Extract the days prior to each checkpoint
                    dates_range = date_dict[innerkey]
                    days = df.loc[df['dates'].between(dates_range[0], dates_range[1])]

                    if not days.empty:
                        # Ensure days_to_output is not larger than the number of available days
                        num_days_available = len(days)
                        num_days_to_extract = min(days_to_output, num_days_available)

                        # Get the specified number of days of data before the survey
                        day_values = days.tail(num_days_to_extract).iloc[:, 1:].values.flatten().tolist()  # Assuming the first column is 'dates' and we need the rest

                        if stressState == 'Low Stress':
                            low_days.extend(day_values)
                        elif stressState == 'High Stress':
                            high_days.extend(day_values)

    # Convert lists to a format suitable for boxplot
    high_days = [value for value in high_days if not pd.isna(value)]
    low_days = [value for value in low_days if not pd.isna(value)]

    # Calculate statistics
    high_mean = np.mean(high_days)
    low_mean = np.mean(low_days)
    high_median = np.median(high_days)
    low_median = np.median(low_days)
    high_std = np.std(high_days)
    low_std = np.std(low_days)

    # Print statistics
    print("High Stress Group Statistics:")
    print(f"Mean: {high_mean}")
    print(f"Median: {high_median}")
    print(f"Standard Deviation: {high_std}")
    print("\nLow Stress Group Statistics:")
    print(f"Mean: {low_mean}")
    print(f"Median: {low_median}")
    print(f"Standard Deviation: {low_std}")

    # Create the box plot with enhanced styling
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=[high_days, low_days], palette="Set3")
    plt.xticks([0, 1], ['High Stress', 'Low Stress'])
    plt.title(f'Box plot of High Stress vs Low Stress\n(Days: Last {days_to_output}, Total Data Threshold: {total_data_threshold}%, Pre-Survey Threshold: {pre_survey_threshold}%)')
    plt.ylabel('Values')

    # Add statistics to the plot
    plt.text(0, high_mean, f'Mean: {high_mean:.2f}\nMedian: {high_median:.2f}\nStd: {high_std:.2f}', horizontalalignment='center', size='medium', color='black', weight='semibold')
    plt.text(1, low_mean, f'Mean: {low_mean:.2f}\nMedian: {low_median:.2f}\nStd: {low_std:.2f}', horizontalalignment='center', size='medium', color='black', weight='semibold')

    plt.show()

# Example usage:
for val in [1,3,7,10,15,30]:
  for tup in [(0,0),(40,50)]:
    plot_stress_levels(pre_checkpoint_month, df_omnis, days_to_output=val, total_data_threshold=tup[0], pre_survey_threshold=tup[1])

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

def plot_stress_levels(pre_checkpoint_month, df_omnis, days_to_output=7, total_data_threshold=40, pre_survey_threshold=50):
    # Initialize lists to hold the specified number of day values for high and low stress groups
    high_days = []
    low_days = []

    # Print the dates column for verification
    print(pre_checkpoint_month['DTUW'])

    # Iterate through each row in df_omnis
    for idx, row in df_omnis.iterrows():
        identifier = row['Global_Deidentified']
        df = pre_checkpoint_month[identifier]
        date_dict = pre_checkpoint_month[identifier + 'c_dates']
        total_present = row['% All Data']

        if total_present > total_data_threshold:  # Check if the participant has more than the specified percentage of their total data present
            for i in range(1, 7):  # Loop through c1 to c6
                innerkey = f'c{i}'
                stressKey = 'Stress Level' + f' c{i}'
                stressState = row[stressKey]
                present_pre_survey = row['% Present 30 before Date ' + innerkey]

                # Check if innerkey exists in date_dict and present_pre_survey is more than the specified threshold
                if innerkey in date_dict and present_pre_survey > pre_survey_threshold:
                    # Extract the days prior to each checkpoint
                    dates_range = date_dict[innerkey]
                    days = df.loc[df['dates'].between(dates_range[0], dates_range[1])]

                    if not days.empty:
                        # Ensure days_to_output is not larger than the number of available days
                        num_days_available = len(days)
                        num_days_to_extract = min(days_to_output, num_days_available)

                        # Get the specified number of days of data before the survey
                        day_values = days.tail(num_days_to_extract).iloc[:, 1:].values.flatten().tolist()  # Assuming the first column is 'dates' and we need the rest

                        if stressState == 'Low Stress':
                            low_days.extend(day_values)
                        elif stressState == 'High Stress':
                            high_days.extend(day_values)

    # Convert lists to a format suitable for boxplot
    high_days = [value for value in high_days if not pd.isna(value)]
    low_days = [value for value in low_days if not pd.isna(value)]

    # Calculate statistics
    high_mean = np.mean(high_days)
    low_mean = np.mean(low_days)
    high_median = np.median(high_days)
    low_median = np.median(low_days)
    high_std = np.std(high_days)
    low_std = np.std(low_days)

    # Print statistics
    print("High Stress Group Statistics:")
    print(f"Mean: {high_mean}")
    print(f"Median: {high_median}")
    print(f"Standard Deviation: {high_std}")
    print(f"Data Points: {len(high_days)}")
    print("\nLow Stress Group Statistics:")
    print(f"Mean: {low_mean}")
    print(f"Median: {low_median}")
    print(f"Standard Deviation: {low_std}")
    print(f"Data Points: {len(low_days)}")

    # Create the box plot with enhanced styling
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=[high_days, low_days], palette=[(1, 0, 0, 0.6), (0, 1, 0, 0.6)])
    plt.xticks([0, 1], ['High Stress', 'Low Stress'])
    plt.title(f'Box plot of High Stress vs Low Stress\n(Days: Last {days_to_output}, Total Data Threshold: {total_data_threshold}%, Pre-Survey Threshold: {pre_survey_threshold}%)')
    plt.ylabel('Values')

    # Add statistics to the plot
    plt.text(0, high_mean, f'Mean: {high_mean:.2f}\nMedian: {high_median:.2f}\nStd: {high_std:.2f}\nN: {len(high_days)}',
             horizontalalignment='center', size='medium', color='black', weight='semibold', bbox=dict(facecolor='white', alpha=0.6))
    plt.text(1, low_mean, f'Mean: {low_mean:.2f}\nMedian: {low_median:.2f}\nStd: {low_std:.2f}\nN: {len(low_days)}',
             horizontalalignment='center', size='medium', color='black', weight='semibold', bbox=dict(facecolor='white', alpha=0.6))

    plt.show()

# Example usage:
for val in [1, 3, 7, 10, 15, 30]:
    for tup in [(0, 0), (40, 50)]:
        plot_stress_levels(pre_checkpoint_month, df_omnis, days_to_output=val, total_data_threshold=tup[0], pre_survey_threshold=tup[1])

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from scipy.stats import ttest_ind, mannwhitneyu, levene

def plot_stress_levels(pre_checkpoint_month, df_omnis, days_to_output=7, total_data_threshold=40, pre_survey_threshold=50):
    # Initialize lists to hold the specified number of day values for high and low stress groups
    high_days = []
    low_days = []

    # Print the dates column for verification
    print(pre_checkpoint_month['DTUW'])

    # Iterate through each row in df_omnis
    for idx, row in df_omnis.iterrows():
        identifier = row['Global_Deidentified']
        df = pre_checkpoint_month[identifier]
        date_dict = pre_checkpoint_month[identifier + 'c_dates']
        total_present = row['% All Data']

        if total_present > total_data_threshold:  # Check if the participant has more than the specified percentage of their total data present
            for i in range(1, 7):  # Loop through c1 to c6
                innerkey = f'c{i}'
                stressKey = 'Stress Level' + f' c{i}'
                stressState = row[stressKey]
                present_pre_survey = row['% Present 30 before Date ' + innerkey]

                # Check if innerkey exists in date_dict and present_pre_survey is more than the specified threshold
                if innerkey in date_dict and present_pre_survey > pre_survey_threshold:
                    # Extract the days prior to each checkpoint
                    dates_range = date_dict[innerkey]
                    days = df.loc[df['dates'].between(dates_range[0], dates_range[1])]

                    if not days.empty:
                        # Ensure days_to_output is not larger than the number of available days
                        num_days_available = len(days)
                        num_days_to_extract = min(days_to_output, num_days_available)

                        # Get the specified number of days of data before the survey
                        day_values = days.tail(num_days_to_extract).iloc[:, 1:].values.flatten().tolist()  # Assuming the first column is 'dates' and we need the rest

                        if stressState == 'Low Stress':
                            low_days.extend(day_values)
                        elif stressState == 'High Stress':
                            high_days.extend(day_values)

    # Convert lists to a format suitable for boxplot
    high_days = [value for value in high_days if not pd.isna(value)]
    low_days = [value for value in low_days if not pd.isna(value)]

    # Calculate statistics
    high_mean = np.mean(high_days)
    low_mean = np.mean(low_days)
    high_median = np.median(high_days)
    low_median = np.median(low_days)
    high_std = np.std(high_days)
    low_std = np.std(low_days)
    high_count = len(high_days)
    low_count = len(low_days)

    # Print statistics
    print("High Stress Group Statistics:")
    print(f"Mean: {high_mean}")
    print(f"Median: {high_median}")
    print(f"Standard Deviation: {high_std}")
    print(f"Data Points: {high_count}")
    print("\nLow Stress Group Statistics:")
    print(f"Mean: {low_mean}")
    print(f"Median: {low_median}")
    print(f"Standard Deviation: {low_std}")
    print(f"Data Points: {low_count}")

    # Statistical Tests
    # T-Test (Welch's t-test)
    t_stat, p_value = ttest_ind(high_days, low_days, equal_var=False)
    print(f"T-Test: t-statistic = {t_stat}, p-value = {p_value}")
    if p_value < 0.05:
        print("The difference in means between the high stress and low stress groups is statistically significant.")
    else:
        print("The difference in means between the high stress and low stress groups is not statistically significant.")

    # Mann-Whitney U Test
    u_stat, u_p_value = mannwhitneyu(high_days, low_days)
    print(f"Mann-Whitney U Test: U-statistic = {u_stat}, p-value = {u_p_value}")
    if u_p_value < 0.05:
        print("There is a statistically significant difference in the distributions of the high stress and low stress groups.")
    else:
        print("There is no statistically significant difference in the distributions of the high stress and low stress groups.")

    # Levene's Test for equal variances
    levene_stat, levene_p_value = levene(high_days, low_days)
    print(f"Levene's Test: W-statistic = {levene_stat}, p-value = {levene_p_value}")
    if levene_p_value < 0.05:
        print("The variances of the high stress and low stress groups are significantly different.")
    else:
        print("The variances of the high stress and low stress groups are not significantly different.")

    # Effect Size (Cohen's d)
    def cohen_d(x, y):
        nx = len(x)
        ny = len(y)
        dof = nx + ny - 2
        return (np.mean(x) - np.mean(y)) / np.sqrt(((nx - 1) * np.var(x) + (ny - 1) * np.var(y)) / dof)

    effect_size = cohen_d(high_days, low_days)
    print(f"Effect Size (Cohen's d) = {effect_size}")

    # Create the box plot with enhanced styling
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=[high_days, low_days], palette=[(1, 0, 0, 0.6), (0, 1, 0, 0.6)])
    plt.xticks([0, 1], ['High Stress', 'Low Stress'])
    plt.title(f'Box plot of High Stress vs Low Stress\n(Days: Last {days_to_output}, Total Data Threshold: {total_data_threshold}%, Pre-Survey Threshold: {pre_survey_threshold}%)')
    plt.ylabel('Values')

    # Add statistics to the plot
    plt.text(0, high_mean, f'Mean: {high_mean:.2f}\nMedian: {high_median:.2f}\nStd: {high_std:.2f}\nN: {high_count}',
             horizontalalignment='center', size='medium', color='black', weight='semibold', bbox=dict(facecolor='white', alpha=0.6))
    plt.text(1, low_mean, f'Mean: {low_mean:.2f}\nMedian: {low_median:.2f}\nStd: {low_std:.2f}\nN: {low_count}',
             horizontalalignment='center', size='medium', color='black', weight='semibold', bbox=dict(facecolor='white', alpha=0.6))

    plt.show()

# Example usage:
for val in [1, 3, 7, 10, 15, 30]:
    for tup in [(0, 0), (40, 50)]:
        plot_stress_levels(pre_checkpoint_month, df_omnis, days_to_output=val, total_data_threshold=tup[0], pre_survey_threshold=tup[1])

"""# Significance"""

# df --> data frame with first column storing Global_Deidentified and every subsequent column storing a date as the head and the sleep data in the column
# cpdf --> Global_Deidentified in the first column and date taken for each of the 6 surveys for the columns after
# mhdf --> PSS at each checkpoint for each and every participant
# df_omnis --> Global Deidentified in the first column and the all 'Global_Deidentified', '% All Data', 'frac surveys', 'Date Taken ci', '% Present 30 before Date ci', '30 day average pre c1i', '7 day average pre ci', 'PSS Score at ci']
# pre_checkpoint_month --> dictionary mapping Gloabl_Deidentified to their 30 day pre checkpoint data, and their survey dates

"""Histogram to analyze if 30 day averages before a checkpoint are actually variable or if this is too much data smoothing"""

# Assuming your DataFrame is named df_omnis
# Create a copy of the DataFrame to modify
df_modified = df_omnis.copy()

# List of checkpoints
checkpoints = ['c1', 'c2', 'c3', 'c4', 'c5', 'c6']

# Set "30 day average pre ci" to NaN where "% Present 30 before Date ci" < 50%
for ci in checkpoints:
    percent_present_column = f'% Present 30 before Date {ci}'
    average_pre_column = f'30 day average pre {ci}'
    df_modified.loc[df_modified[percent_present_column] < 50, average_pre_column] = pd.NA

# Now plot the histograms
plt.figure(figsize=(12, 8))
for i, ci in enumerate(checkpoints):
    column = f'30 day average pre {ci}'
    plt.subplot(2, 3, i+1)
    plt.hist(df_modified[column].dropna(), bins=25, alpha=0.75, label=f'{column}')
    plt.title(f'Histogram of {column}')
    plt.xlabel('30 day average')
    plt.ylabel('Frequency')
    plt.legend()

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Assuming your DataFrame is named df_omnis
# Create an empty list to collect the valid 30 day averages
valid_averages = []

# List of checkpoints
checkpoints = ['c1', 'c2', 'c3', 'c4', 'c5', 'c6']

# Append valid 30 day averages to the list
for ci in checkpoints:
    percent_present_column = f'% Present 30 before Date {ci}'
    average_pre_column = f'30 day average pre {ci}'
    # Select only the data where "% Present 30 before Date ci" > 50%
    valid_data = df_omnis.loc[df_omnis[percent_present_column] > 50, average_pre_column]
    valid_averages.append(valid_data)

# Concatenate all valid averages into a single Series
all_valid_averages = pd.concat(valid_averages)

# Now plot the histogram
plt.figure(figsize=(10, 6))
plt.hist(all_valid_averages.dropna(), bins=25, alpha=0.5, color = 'r', label=f'30 day average pre ci, num data points : {len(all_valid_averages)}')
plt.title('Combined Histogram of 30 Day Averages Where Present > 50%')
plt.xlabel('30 Day Average')
plt.ylabel('Frequency')
plt.legend()
plt.show()

print(np.std(all_valid_averages))

"""Histogram of all our participants to start to understand what values are more dramatic"""

# Exclude the 'Global_Deidentified' column and flatten the DataFrame to get all data values
data_values = df.loc[:, df.columns != 'Global_Deidentified'].values.flatten()

# Remove NaN values if any
data_values = data_values[~pd.isnull(data_values)]

# Calculate the total number of data points
total_data_points = len(data_values)

# Now plot the histogram
plt.figure(figsize=(10, 6))
plt.hist(data_values, bins=100, alpha=0.5, color = 'r')  # You can adjust the number of bins as needed
plt.title('Histogram of All Data Values')
plt.xlabel('Data Values')
plt.ylabel('Frequency')
plt.legend([f'Total points: {total_data_points}'])
plt.show()

print(np.std(data_values))
print(np.mean(data_values))
print(np.median(data_values))

"""Add last column to the df_omnis connecting the low\high\medium stress states to a classification that is in line with the manner in which Ziv classified.

"continually increasing" : participant is low or medium stress in each of the first Stress Level c1',  'Stress Level c2', 'Stress Level c3', with at least one entry in the low category, and medium or high stress in  'Stress Level c4', 'Stress Level c5', 'Stress Level c6' with at least one entry in high stress

"continually decreasing" : medium or high stress in Stress Level c1',  'Stress Level c2', 'Stress Level c3' with at least one entry in high stress and medium or low stress in 'Stress Level c4', 'Stress Level c5', 'Stress Level c6' with at least one entry in hight stress

"always high" : No entries with low stress, at least 2 entries with high stress

"always low" : no entries with high stress, at least 2 entries with low stress

"fluctuators" : everyone else

"""

def classify_stress(row):
    stress_levels = row[['Stress Level c1', 'Stress Level c2', 'Stress Level c3',
                         'Stress Level c4', 'Stress Level c5', 'Stress Level c6']]

    # Check if all entries are 'Medium Stress'
    if all(x == 'Medium Stress' for x in stress_levels):
        return 'always medium'
    # Check for continually increasing pattern
    if all(x in ['Low Stress', 'Medium Stress'] for x in stress_levels[:3]) and \
       all(x in ['Medium Stress', 'High Stress'] for x in stress_levels[3:]):
        return 'continually increasing'
    # Check for continually decreasing pattern
    if all(x in ['Medium Stress', 'High Stress'] for x in stress_levels[:3]) and \
       all(x in ['Medium Stress', 'Low Stress'] for x in stress_levels[3:]):
        return 'continually decreasing'
    # Check if there are no 'Low Stress' entries for always high
    if all(x != 'Low Stress' for x in stress_levels):
        return 'always high'
    # Check if there are no 'High Stress' entries for always low
    if all(x != 'High Stress' for x in stress_levels) and \
      sum(x == 'Low Stress' for x in stress_levels) >= 3:
        return 'always low'

    return 'fluctuators'

df_omnis['Stress Classification'] = df_omnis.apply(classify_stress, axis=1)

classifications = ['always medium', 'always low', 'always high', 'continually increasing', 'continually decreasing', 'fluctuators']
classification_counts_dict = {}
classification_sets_dict = {}

for cls in classifications:
    mask = df_omnis['Stress Classification'] == cls
    classification_counts_dict[cls] = mask.sum()
    classification_sets_dict[cls] = set(df_omnis.loc[mask, 'Global_Deidentified'])

for cls, count in classification_counts_dict.items():
    print(f"{cls} has {count} participants")
    print(f"Here are the identifiers for {cls}: {classification_sets_dict[cls]}")

"""Plot how often people variate from their 30 average/median within a certain number of day --> signficance testing for my other plots where I look for trends

explore other trends, how often do we increase for 3 days in a row, decrease? explore, keep open mind, and find signficance
"""

import pandas as pd
import matplotlib.pyplot as plt

# Assuming pre_checkpoint_month, df_omnis, classification_sets_dict, and classifications are defined elsewhere

# Exclude items with 'c_dates' in keys
data_dict = {GD: df for GD, df in pre_checkpoint_month.items() if "c_dates" not in GD}

data = pd.DataFrame()  # Initialize an empty DataFrame for data

differences = []
# Analyze data and populate counts
for GD, data_frame in data_dict.items():
    for cls in classifications:
        if GD in classification_sets_dict[cls]:  # Check if GD belongs to the current classification
            for i in range(1, 7):

                percent_present = df_omnis.loc[df_omnis['Global_Deidentified'] == GD, f'% Present 30 before Date c{i}'].iloc[0]
                if percent_present > 50:
                    innerkey = f'c{i}'
                    average = df_omnis.loc[df_omnis['Global_Deidentified'] == GD, f'30 day average pre c{i}'].iloc[0]
                    data_frame['dates'] = pd.to_datetime(data_frame['dates'])  # Convert 'dates' column to datetime once

                    date_list = (data_frame[innerkey].dropna()).tolist()
                    differences_list = [value - average for value in date_list]

                    differences += differences_list


# Plotting all histograms on one axis
plt.figure(figsize=(10, 8))
colors = ['blue', 'green', 'red', 'purple', 'orange', 'brown']  # Different color for each classification

plt.hist(differences, bins = 60, color=colors[3])  # Ensure data is properly structured for histogram
plt.xlabel('Difference from 30 day average')
plt.ylabel('Frequency')
plt.title('Number of Days increasing before a checkpoint')
plt.legend(title='Participant Groups and Counts', loc='upper right')

plt.show()
print("Standard Deviation from 30 day average : ", np.std(differences))

import pandas as pd
import matplotlib.pyplot as plt

# Assuming pre_checkpoint_month, df_omnis, classifications, and classification_sets_dict are defined elsewhere

# Prepare a data dictionary excluding certain items based on 'c_dates'
data_dict = {GD: df for GD, df in pre_checkpoint_month.items() if "c_dates" not in GD}

# Dictionary of dictionaries for counts
counts_dict = {cls: {i: 0 for i in range(1, 8)} for cls in classifications}

added_columns = {}

differences = []
for GD, data_frame in data_dict.items():
  added_columns[GD] = {}
  for i in range(1, 7):

      diff_key = f'avg difference pre c{i}'
      added_columns[GD][diff_key] = []
      innerkey = f'c{i}'

      percent_present = df_omnis.loc[df_omnis['Global_Deidentified'] == GD, f'% Present 30 before Date c{i}'].iloc[0]
      if percent_present > 50:
          average = df_omnis.loc[df_omnis['Global_Deidentified'] == GD, f'30 day average pre c{i}'].iloc[0]
          values = data_frame[innerkey].dropna()

          # Calculate differences and append to the list
          diffs = []
          for data in values[-8:-1]:
              diff = data - average
              differences.append(diff)
              diffs.append(abs(diff))
          added_columns[GD][diff_key].append(sum(diffs)/len(diffs))
      else:
          added_columns[GD][diff_key].append(np.nan)


# Only plot if there are differences to plot
if differences:
    plt.hist(differences, bins= 100, edgecolor='black')
    plt.xlabel('Difference from 30-Day Average')
    plt.ylabel('Frequency')
    plt.title('Differences in Last 7 Days from 30-Day Average')
    # No legend here unless you have groups or categories to associate with the differences.
    plt.show()
else:
    print("No differences to plot.")

print(np.std(differences))
seven_day_std = np.std(differences)

print(added_columns)

prediction_dict = {}
validation_dict = {}

for idx, row in df_omnis.iterrows():
  participant = row['Global_Deidentified']
  percent_all_data = row['% All Data']
  if percent_all_data > 0:
    for i in range(1,7):
      innerkey = f'c{i}'
      date_survey_taken = f'Date Taken c{i}'
      present_pre_survey_key = f'% Present 30 before Date c{i}'
      average_pre_survey = row[f'30 day average pre c{i}']
      stress_key = f'Stress Level c{i}'
      stress_classificaion_at_survey = row[stress_key]
      count = 0

      if row[present_pre_survey_key] > 40:
        # Data_frame for specific Participant w columns
        # dates  c1  c2  c3  c4  c5  c6
        data_frame = pre_checkpoint_month[participant]

        # Full series list of value before a survey
        values_pre_survey = data_frame[innerkey]
        # How to access the non_nan values :
        values_pre_survey = values_pre_survey[values_pre_survey.notnull()]
        for val in values_pre_survey[-8:-1]:
          if val > average_pre_survey + (1 * seven_day_std) or val < average_pre_survey - (1 * seven_day_std):
          # if val > (average_pre_survey + (.5 * seven_day_std)) or val < (average_pre_survey - (.5 * seven_day_std)):
            count +=1

        prediction_dict[(participant, innerkey)] = []
        validation_dict[(participant, innerkey)] = stress_classificaion_at_survey

        if count >= 4:
          prediction_dict[(participant, innerkey)].append("Medium Stress")
          prediction_dict[(participant, innerkey)].append("High Stress")
        else :
          #prediction_dict[(participant, innerkey)].append("Medium Stress")
          prediction_dict[(participant, innerkey)].append("Low Stress")

accurate = 0
total = 0
for participant_cp, pred in prediction_dict.items():
  if "High Stress" in pred: #or "Medium Stress" in pred:
    total += 1
    if validation_dict[participant_cp] in pred:
      accurate +=1

# Of all the times that I predicted high stress or medium stress
# I was right 64% of the time

print(f"When I predicted a participant would be High or Medium Stress, I was right : {(accurate/total) *100}% of the time")


count_stress = 0
for idx, row in df_omnis.iterrows():
  for i in range(1, 7):
    innerkey = f'c{i}'
    if (row['Global_Deidentified'], innerkey) in prediction_dict.keys():
      if row[f'Stress Level c{i}'] == 'High Stress': #or row[f'Stress Level c{i}'] == 'Medium Stress': #or row[f'Stress Level c{i}'] == 'Low Stress':
          count_stress += 1


print(f"Of all the times a participant was either High I predicted it {(accurate/count_stress) * 100} % of the time")
# May need to write acutal predictor/linear regression or binary classification

# Let's update the code to use the actual column headings and titles from the provided DataFrame screenshot.
# As before, we will use the hypothetical data structure as the actual DataFrame is not provided.

# We'll create a function that can be used to generate the plots from the DataFrame `df_omnis`.
'''
changing to poppulate with k-means clustering derived centers

5.60588235
13.12735849
20.33793103

#CHANGE THE HIGH LOW STRESS RANGES

ziv values :

low = 7
mid = 20
high = 33

'''
def generate_stress_plots(df):
    # Define the stress level categories based on the PSS Score ranges
    stress_levels = {
        'Low Stress': (0, 13),
        'Medium Stress': (13, 26.0),
        'High Stress': (26, 40)
    }

    # Function to categorize stress levels based on PSS Score
    def categorize_stress(row):
        for level, (low, high) in stress_levels.items():
            if low <= row <= high:
                return level
        #return 'Unknown'

    # Categorize stress for each PSS Score column and calculate the average 30 day pre c{i} for each category
    results = {}
    for column in df.columns:
        if column.startswith('PSS Score at '):
            stress_column = 'Stress Level ' + column.split(' ')[-1]
            df[stress_column] = df[column].apply(categorize_stress)

            # Calculating average for 30 day average pre column corresponding to the PSS Score column
            avg_column = '30 day average pre ' + column.split(' ')[-1]
            if avg_column in df.columns:
                results[avg_column] = df.groupby(stress_column)[avg_column].mean()

# Call the function with hypothetical data
generate_stress_plots(df_omnis)

import pandas as pd
import numpy as np

# Assuming df_omnis is already loaded with your data

# Define the checkpoints
checkpoints = range(1, 7)  # Assuming 6 checkpoints

# Initialize dictionaries to store sums and counts
sums_high = {}
sums_low = {}
counts_high = {}
counts_low = {}

# Initialize sums and counts to zero for each unique identifier
for id in df_omnis['Global_Deidentified'].unique():
    sums_high[id] = 0.0
    sums_low[id] = 0.0
    counts_high[id] = 0
    counts_low[id] = 0

# Loop through each checkpoint and aggregate the data
for i in checkpoints:
    column = f'7 day average pre c{i}'
    percent_present_column = f'% Present 30 before Date c{i}'

    # Process High Stress where data is more than 50% present
    mask_high = (df_omnis[f'Stress Level c{i}'] == 'High Stress') & df_omnis[column].notna() & (df_omnis[percent_present_column] > 50)
    for idx, group in df_omnis.loc[mask_high].groupby('Global_Deidentified'):
        sums_high[idx] += group[column].sum()
        counts_high[idx] += group[column].count()

    # Process Low Stress where data is more than 50% present
    mask_low = (df_omnis[f'Stress Level c{i}'] == 'Low Stress') & df_omnis[column].notna() & (df_omnis[percent_present_column] > 50)
    for idx, group in df_omnis.loc[mask_low].groupby('Global_Deidentified'):
        sums_low[idx] += group[column].sum()
        counts_low[idx] += group[column].count()

# Convert sums and counts into Series for easier manipulation
sums_high_series = pd.Series(sums_high)
sums_low_series = pd.Series(sums_low)
counts_high_series = pd.Series(counts_high)
counts_low_series = pd.Series(counts_low)

# Calculate the averages
averages_high = sums_high_series / counts_high_series.replace(0, np.nan)
averages_low = sums_low_series / counts_low_series.replace(0, np.nan)

# Combine the results into a DataFrame
final_averages = pd.DataFrame({
    'Global_Deidentified': df_omnis['Global_Deidentified'].unique(),
    'high stress 7 day average': averages_high,
    'low stress 7 day average': averages_low
}).fillna(np.nan)  # Handle NaNs if no counts exist

# Reset the index for the final DataFrame
final_averages.reset_index(drop=True, inplace=True)

# Show the final DataFrame
print(final_averages.head())

import pandas as pd
import numpy as np

# Assuming df_omnis is already loaded with your data

# Define the checkpoints
checkpoints = range(1, 7)  # Assuming 6 checkpoints

# Initialize dictionaries to store sums and counts
sums_high = {}
sums_low = {}
counts_high = {}
counts_low = {}

# Initialize sums and counts to zero for each unique identifier
for id in df_omnis['Global_Deidentified'].unique():
    sums_high[id] = 0.0
    sums_low[id] = 0.0
    counts_high[id] = 0
    counts_low[id] = 0

# Loop through each checkpoint and aggregate the data
for i in checkpoints:
    column = f'7 day average pre c{i}'
    # Process High Stress
    mask_high = (df_omnis[f'Stress Level c{i}'] == 'High Stress') & df_omnis[column].notna()
    for idx, group in df_omnis.loc[mask_high].groupby('Global_Deidentified'):
        sums_high[idx] += group[column].sum()
        counts_high[idx] += group[column].count()

    # Process Low Stress
    mask_low = (df_omnis[f'Stress Level c{i}'] == 'Low Stress') & df_omnis[column].notna()
    for idx, group in df_omnis.loc[mask_low].groupby('Global_Deidentified'):
        sums_low[idx] += group[column].sum()
        counts_low[idx] += group[column].count()

# Convert sums and counts into Series for easier manipulation
sums_high_series = pd.Series(sums_high)
sums_low_series = pd.Series(sums_low)
counts_high_series = pd.Series(counts_high)
counts_low_series = pd.Series(counts_low)

# Calculate the averages
averages_high = sums_high_series / counts_high_series.replace(0, np.nan)
averages_low = sums_low_series / counts_low_series.replace(0, np.nan)

# Combine the results into a DataFrame
final_averages = pd.DataFrame({
    'Global_Deidentified': df_omnis['Global_Deidentified'].unique(),
    'high stress 7 day average': averages_high,
    'low stress 7 day average': averages_low
}).fillna(np.nan)  # Handle NaNs if no counts exist

# Reset the index for the final DataFrame
final_averages.reset_index(drop=True, inplace=True)

# Show the final DataFrame
print(tabulate(final_averages, headers='keys', tablefmt='psql', showindex = False))

import matplotlib.pyplot as plt

# Assuming 'final_averages' is your DataFrame with the required data
# Create a scatter plot
plt.figure(figsize=(10, 6))  # Setting the size of the plot
plt.scatter(final_averages['high stress 7 day average'], final_averages['low stress 7 day average'], alpha=0.5, color='blue')
plt.title('Correlation between High Stress and Low Stress 7 Day Averages')  # Title of the plot
plt.xlabel('High Stress 7 Day Average')  # Label for the x-axis
plt.ylabel('Low Stress 7 Day Average')  # Label for the y-axis
plt.plot(np.arange(90,100,1), np.arange(90,100,1), label='y = x', linestyle = ':', color='red')
plt.grid(True)  # Adding a grid for better readability
plt.show()  # Display the plot

import statsmodels.api as sm

filtered_data = final_averages.dropna(subset=['high stress 7 day average', 'low stress 7 day average'])

# Fit regression model
X = sm.add_constant(filtered_data['high stress 7 day average'])  # Adding a constant for the intercept
model = sm.OLS(filtered_data['low stress 7 day average'], X).fit()
print(model.summary())

print('\n\n---------------------------------------------------------------------\n\n')

from scipy.stats import pearsonr

# Calculate Pearson correlation and the p-value
corr, p_value = pearsonr(filtered_data['high stress 7 day average'], filtered_data['low stress 7 day average'])
print("Correlation Coefficient:", corr)
print("P-value:", p_value)

print('\n\n---------------------------------------------------------------------\n\n')
import pandas as pd

# Assuming 'filtered_data' is your DataFrame with non-NaN values
correlation = filtered_data['high stress 7 day average'].corr(filtered_data['low stress 7 day average'])
print("Pearson correlation coefficient:", correlation)


print('\n\n---------------------------------------------------------------------\n\n')

import scipy.stats as stats

print(tabulate(df_omnis, headers='keys', tablefmt='psql', showindex = False))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import linregress

def scatter_plot(column_header):
    # Assuming df_omnis is already loaded with your data
    checkpoints = range(1, 7)  # Assuming 6 checkpoints

    # Initialize dictionaries to store sums and counts
    sums_high_30 = {}
    sums_low_30 = {}
    counts_high_30 = {}
    counts_low_30 = {}

    # Initialize sums and counts to zero for each unique identifier
    for id in df_omnis['Global_Deidentified'].unique():
        sums_high_30[id] = 0.0
        sums_low_30[id] = 0.0
        counts_high_30[id] = 0
        counts_low_30[id] = 0

    # Loop through each checkpoint and aggregate the data
    for i in checkpoints:
        day_30_column = column_header[:-2] + f'c{i}'
        percent_present_column = f'% Present 30 before Date c{i}'

        # Process High Stress where data is more than 50% present
        mask_high = (df_omnis[f'Stress Level c{i}'] == 'High Stress') & df_omnis[day_30_column].notna() & (df_omnis[percent_present_column] > 50)
        for idx, group in df_omnis.loc[mask_high].groupby('Global_Deidentified'):
            sums_high_30[idx] += group[day_30_column].sum()
            counts_high_30[idx] += group[day_30_column].count()

        # Process Low Stress where data is more than 50% present
        mask_low = (df_omnis[f'Stress Level c{i}'] == 'Low Stress') & df_omnis[day_30_column].notna() & (df_omnis[percent_present_column] > 50)
        for idx, group in df_omnis.loc[mask_low].groupby('Global_Deidentified'):
            sums_low_30[idx] += group[day_30_column].sum()
            counts_low_30[idx] += group[day_30_column].count()

    # Convert sums and counts into Series for easier manipulation
    sums_high_30_series = pd.Series(sums_high_30)
    sums_low_30_series = pd.Series(sums_low_30)
    counts_high_30_series = pd.Series(counts_high_30)
    counts_low_30_series = pd.Series(counts_low_30)

    # Calculate the averages
    averages_high_30 = sums_high_30_series / counts_high_30_series.replace(0, np.nan)
    averages_low_30 = sums_low_30_series / counts_low_30_series.replace(0, np.nan)

    # Combine the results into a DataFrame
    final_averages_30 = pd.DataFrame({
        'Global_Deidentified': df_omnis['Global_Deidentified'].unique(),
        'high stress 30 day average': averages_high_30,
        'low stress 30 day average': averages_low_30
    }).fillna(np.nan)  # Handle NaNs if no counts exist

    # Reset the index for the final DataFrame
    final_averages_30.reset_index(drop=True, inplace=True)

    # Filter out NaN values for statistics and regression
    valid_data = final_averages_30.dropna(subset=['high stress 30 day average', 'low stress 30 day average'])

    # Calculate and print general statistics
    print(f"Statistics for High Stress Group ({column_header[:-2]}):")
    print(f"  Mean: {valid_data['high stress 30 day average'].mean():.2f}")
    print(f"  Std Dev: {valid_data['high stress 30 day average'].std():.2f}")
    print(f"  Min: {valid_data['high stress 30 day average'].min():.2f}")
    print(f"  Max: {valid_data['high stress 30 day average'].max():.2f}")
    print()
    print(f"Statistics for Low Stress Group ({column_header[:-2]}):")
    print(f"  Mean: {valid_data['low stress 30 day average'].mean():.2f}")
    print(f"  Std Dev: {valid_data['low stress 30 day average'].std():.2f}")
    print(f"  Min: {valid_data['low stress 30 day average'].min():.2f}")
    print(f"  Max: {valid_data['low stress 30 day average'].max():.2f}")
    print()

    # Create a scatter plot
    plt.figure(figsize=(10, 6))
    plt.scatter(valid_data['high stress 30 day average'], valid_data['low stress 30 day average'], alpha=0.5, color='red', label='Data points')

    min_val = min(valid_data['high stress 30 day average'].min(), valid_data['low stress 30 day average'].min())
    max_val = max(valid_data['high stress 30 day average'].max(), valid_data['low stress 30 day average'].max())

    plt.plot([min_val, max_val], [min_val, max_val], linestyle=':', color='purple', label='y = x')

    # Fit line of best fit
    if not valid_data.empty:
        slope, intercept, r_value, p_value, std_err = linregress(valid_data['high stress 30 day average'], valid_data['low stress 30 day average'])
        plt.plot(valid_data['high stress 30 day average'], intercept + slope*valid_data['high stress 30 day average'], 'k:', alpha=0.5, label=f'Best fit line (r={r_value:.2f})')

    plt.title('Correlation between High Stress and Low Stress ' + column_header[:-2] + 'check')
    plt.xlabel('High Stress ' + column_header[:-2] + 'check')
    plt.ylabel('Low Stress ' + column_header[:-2] + 'check')
    plt.legend()
    plt.grid(True)
    plt.show()

keys = ['Global_Deidentified', '% All Data', 'frac surveys', f'Date Taken c{i}']
keys.append(f'% Present 30 before Date c{i}')
keys.append(f'30 day average pre c{i}')
keys.append(f'avg Difference 7 days pre c{i}')
keys.append(f'7 day average pre c{i}')
keys.append(f'avg Difference 3 days pre c{i}')
keys.append(f'7 max - min pre c{i}')
keys.append(f'days increasing pre c{i}')
keys.append(f'30 max - min pre c{i}')
#keys.append(f'15 max - min pre c{i}')
keys.append(f'3 max - min pre c{i}')
keys.append(f'ratio above below 30 c{i}')
keys.append(f'ratio above below 7 c{i}')
keys.append(f'3 day average pre c{i}')
keys.append(f'9 day average pre c{i}')
keys.append(f'days decreasing pre c{i}')
keys.append(f'Day before c{i}')
keys.append(f'PSS Score at c{i}')

for key in keys[3:-1]:
    if 'Date' not in key:
        scatter_plot(key)

import pandas as pd
import numpy as np

# Assuming df_omnis is already loaded into your environment

# Initialize new columns with NaNs
checkpoints = ['c1', 'c2', 'c3', 'c4', 'c5', 'c6']
new_columns = [f'avg difference pre {cp}' for cp in checkpoints]
for col in new_columns:
    df_omnis[col] = np.nan

# Update each 'avg difference pre c{i}' column from added_columns
for key, values in added_columns.items():
    for cp in checkpoints:
        column_name = f'avg difference pre {cp}'
        if column_name in values:
            # Locate the index for the specific Global_Deidentified value
            index = df_omnis[df_omnis['Global_Deidentified'] == key].index
            # Update the DataFrame at the found index and specific column
            df_omnis.loc[index, column_name] = values[column_name][0]

# Now df_omnis should have the updated columns if the data exists in added_columns

# Now df_omnis has the updated 'avg difference pre c6' column with other columns initialized to NaN
# Show the final DataFrame
print(tabulate(df_omnis, headers='keys', tablefmt='psql', showindex = False))
print(df_omnis.columns)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Assuming df_omnis is already loaded with your data
checkpoints = range(1, 7)  # Assuming 6 checkpoints

# Initialize dictionaries to store sums and counts
sums_high_diff = {}
sums_low_diff = {}
counts_high_diff = {}
counts_low_diff = {}

# Initialize sums and counts to zero for each unique identifier
for id in df_omnis['Global_Deidentified'].unique():
    sums_high_diff[id] = 0.0
    sums_low_diff[id] = 0.0
    counts_high_diff[id] = 0
    counts_low_diff[id] = 0

# Loop through each checkpoint and aggregate the data
for i in checkpoints:
    diff_column = f'avg difference pre c{i}'
    percent_present_column = f'% Present 30 before Date c{i}'

    # Process High Stress where data is more than 50% present
    mask_high = (df_omnis[f'Stress Level c{i}'] == 'High Stress') & df_omnis[diff_column].notna() & (df_omnis[percent_present_column] > 50)
    for idx, group in df_omnis.loc[mask_high].groupby('Global_Deidentified'):
        sums_high_diff[idx] += group[diff_column].sum()
        counts_high_diff[idx] += group[diff_column].count()

    # Process Low Stress where data is more than 50% present
    mask_low = (df_omnis[f'Stress Level c{i}'] == 'Low Stress') & df_omnis[diff_column].notna() & (df_omnis[percent_present_column] > 50)
    for idx, group in df_omnis.loc[mask_low].groupby('Global_Deidentified'):
        sums_low_diff[idx] += group[diff_column].sum()
        counts_low_diff[idx] += group[diff_column].count()

# Convert sums and counts into Series for easier manipulation
sums_high_diff_series = pd.Series(sums_high_diff)
sums_low_diff_series = pd.Series(sums_low_diff)
counts_high_diff_series = pd.Series(counts_high_diff)
counts_low_diff_series = pd.Series(counts_low_diff)

# Calculate the averages
averages_high_diff = sums_high_diff_series / counts_high_diff_series.replace(0, np.nan)
averages_low_diff = sums_low_diff_series / counts_low_diff_series.replace(0, np.nan)

# Combine the results into a DataFrame
final_averages_diff = pd.DataFrame({
    'Global_Deidentified': df_omnis['Global_Deidentified'].unique(),
    'high stress avg difference': averages_high_diff,
    'low stress avg difference': averages_low_diff
}).fillna(np.nan)  # Handle NaNs if no counts exist

# Reset the index for the final DataFrame
final_averages_diff.reset_index(drop=True, inplace=True)

# Create a scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(final_averages_diff['high stress avg difference'], final_averages_diff['low stress avg difference'], alpha=0.5, color='green')
plt.title('Correlation between High Stress and Low Stress Avg Differences')
plt.xlabel('High Stress Avg Difference')
plt.xticks(np.arange(0,1.8,.2))
plt.yticks(np.arange(0,1.8,.2))
plt.plot(np.arange(0,2,.1), np.arange(0,2,.1), label='y = x', linestyle = ':', color='red')
plt.ylabel('Low Stress Avg Difference')
plt.grid(True)
plt.show()

print(df_omnis['7 day average pre c5'])

import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Assuming 'df' is your DataFrame
num_checkpoints = 6  # Update this if you have more checkpoints

for i in range(1, num_checkpoints + 1):
    # Prepare the data for each checkpoint
    avg_col = f'7 day average pre c{i}'
    pss_col = f'PSS Score at c{i}'
    data = df_omnis[[avg_col, pss_col]].dropna()  # Dropping rows with missing data

    # K-Means Clustering
    kmeans = KMeans(n_clusters=3, random_state=0)  # Adjust the number of clusters as needed
    clusters = kmeans.fit_predict(data)

    # Plotting
    plt.figure(figsize=(10, 6))
    plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=clusters, cmap='viridis', label=f'Checkpoint {i}')
    plt.xlabel(avg_col)
    plt.ylabel(pss_col)
    plt.title(f'K-Means Clustering for Checkpoint {i}')
    plt.colorbar(label='Cluster')
    plt.show()

import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import numpy as np

# Assuming 'df' is your DataFrame
num_checkpoints = 6  # Update this if you have more checkpoints
colors = plt.cm.viridis(np.linspace(0, 1, num_checkpoints))  # Generate distinct colors for each checkpoint

plt.figure(figsize=(12, 8))

for i in range(1, num_checkpoints + 1):
    # Prepare the data for each checkpoint
    avg_col = f'7 day average pre c{i}'
    pss_col = f'PSS Score at c{i}'
    data = df_omnis[[avg_col, pss_col]].dropna()  # Dropping rows with missing data

    # K-Means Clustering
    kmeans = KMeans(n_clusters=3, random_state=0)  # Adjust the number of clusters as needed
    clusters = kmeans.fit_predict(data)

    # Plotting on the same axes for comparison
    plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=colors[i-1], label=f'Checkpoint {i}', alpha=0.6, edgecolor='k')

plt.xlabel('7 day average pre c{i}')
plt.ylabel('PSS Score at c{i}')
plt.title('Comparison of K-Means Clustering Across All Checkpoints')
plt.colorbar(plt.cm.ScalarMappable(cmap='viridis'), label='Checkpoint')
plt.legend(title='Checkpoint')
plt.show()

"""# Machine Learning"""

'''
low = 7
mid = 20
high = 33

'''
def generate_stress_plots(df):
    # Define the stress level categories based on the PSS Score ranges
    stress_levels = {
        'Low Stress': (0, 14),
        #'Medium Stress': (13, 26.0),
        'High Stress': (14, 40)
    }

    # Function to categorize stress levels based on PSS Score
    def categorize_stress(row):
        for level, (low, high) in stress_levels.items():
            if low <= row <= high:
                return level
        #return 'Unknown'

    # Categorize stress for each PSS Score column and calculate the average 30 day pre c{i} for each category
    results = {}
    for column in df.columns:
        if column.startswith('PSS Score at '):
            stress_column = 'Stress Level ' + column.split(' ')[-1]
            df[stress_column] = df[column].apply(categorize_stress)

            # Calculating average for 30 day average pre column corresponding to the PSS Score column
            avg_column = '30 day average pre ' + column.split(' ')[-1]
            if avg_column in df.columns:
                results[avg_column] = df.groupby(stress_column)[avg_column].mean()

# Call the function with hypothetical data
generate_stress_plots(df_omnis)

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score

# Load your dataset (uncomment and modify this line to load your dataset)
# df_omnis = pd.read_csv('your_dataset.csv')

# Define features and targets
Features = ['% All Data']
for i in range(1, 7):
    Features.extend([
        f'% Present 30 before Date c{i}', f'30 day average pre c{i}', f'7 day average pre c{i}',
        f'7 max - min pre c{i}', f'days increasing pre c{i}', f'30 max - min pre c{i}',
        f'3 max - min pre c{i}', f'ratio above below 30 c{i}', f'ratio above below 7 c{i}',
        f'3 day average pre c{i}', f'9 day average pre c{i}', f'days decreasing pre c{i}',
        f'avg Difference 7 days pre c{i}', f'Day before c{i}', f'avg Difference 3 days pre c{i}'
    ])

Classification_targets = [f'Stress Level c{i}' for i in range(1, 7)]
Regression_targets = [f'PSS Score at c{i}' for i in range(1, 7)]


# Split data into training and validation sets
validation_size = 20

train_features = df_omnis[Features][validation_size:]
train_classification_targets = df_omnis[Classification_targets][validation_size:]
train_regression_targets = df_omnis[Regression_targets][validation_size:]

validation_features = df_omnis[Features][:validation_size]
validation_classification_targets = df_omnis[Classification_targets][:validation_size]
validation_regression_targets = df_omnis[Regression_targets][:validation_size]

# Fill NaN values in classification targets with the mode of the column
for column in Classification_targets:
    if train_classification_targets[column].isnull().sum() > 0:
        mode_value = train_classification_targets[column].mode()[0]
        train_classification_targets[column].fillna(mode_value, inplace=True)

    if validation_classification_targets[column].isnull().sum() > 0:
        mode_value = validation_classification_targets[column].mode()[0]
        validation_classification_targets[column].fillna(mode_value, inplace=True)

# Encode the stress level columns
label_encoders = {}
for column in Classification_targets:
    label_encoders[column] = LabelEncoder()
    train_classification_targets[column] = label_encoders[column].fit_transform(train_classification_targets[column])
    validation_classification_targets[column] = label_encoders[column].transform(validation_classification_targets[column])

# Fill NaN values in regression targets with the mean of the column
for column in Regression_targets:
    if train_regression_targets[column].isnull().sum() > 0:
        mean_value = train_regression_targets[column].mean()
        train_regression_targets[column].fillna(mean_value, inplace=True)

    if validation_regression_targets[column].isnull().sum() > 0:
        mean_value = validation_regression_targets[column].mean()
        validation_regression_targets[column].fillna(mean_value, inplace=True)

# Create an imputer to fill NaN values in features with the mean of each column
imputer = SimpleImputer(strategy='mean')

# Fit the imputer on the training data and transform both training and validation data
train_features = imputer.fit_transform(train_features)
validation_features = imputer.transform(validation_features)

# Standardize the features
scaler = StandardScaler()

# Fit the scaler on the training data and transform both training and validation data
train_features = scaler.fit_transform(train_features)
validation_features = scaler.transform(validation_features)

# Generalize classification task for all surveys
for target_column in Classification_targets:
    # Train the classification model for one target column
    classifier = RandomForestClassifier()
    classifier.fit(train_features, train_classification_targets[target_column])

    # Evaluate the classification model for one target column
    val_predictions_classification = classifier.predict(validation_features)
    print(f"Classification Report for {target_column}:")
    print(classification_report(validation_classification_targets[target_column], val_predictions_classification))

    # Cross-validation scores
    cv_scores = cross_val_score(classifier, train_features, train_classification_targets[target_column], cv=5)
    print(f"Cross-validation scores for {target_column}: {cv_scores}")
    print(f"Average cross-validation score for {target_column}: {cv_scores.mean()}")

# Train the regression model
regressor = RandomForestRegressor()
regressor.fit(train_features, train_regression_targets)

# Evaluate the regression model
val_predictions_regression = regressor.predict(validation_features)

# Calculate and print the Mean Squared Error
mse = mean_squared_error(validation_regression_targets, val_predictions_regression)
print(f'Mean Squared Error: {mse}')

"""Per-Class Metrics
Precision:

The ratio of true positive predictions to the total predicted positives.
Precision = TP / (TP + FP), where TP is True Positives and FP is False Positives.
High precision means that the classifier is accurate when it predicts the positive class.
Recall:

The ratio of true positive predictions to the total actual positives.
Recall = TP / (TP + FN), where FN is False Negatives.
High recall means that the classifier correctly identifies most of the positive examples.
F1-Score:

The harmonic mean of precision and recall.
F1-Score = 2 * (Precision * Recall) / (Precision + Recall).
A good balance between precision and recall. Its useful when you need to take both false positives and false negatives into account.
Support:

The number of actual occurrences of the class in the dataset.
This helps understand how the metrics are influenced by the class distribution.
Overall Metrics
Accuracy:

The ratio of correctly predicted samples to the total samples.
Accuracy = (TP + TN) / (TP + TN + FP + FN), where TN is True Negatives.
Macro Average:

The unweighted average of the precision, recall, and F1-score for all classes.
Treats all classes equally regardless of their support.
Weighted Average:

The average of the precision, recall, and F1-score for all classes, weighted by the number of true instances for each class.
Takes class support into account, useful for imbalanced datasets.
Example Interpretation
For Stress Level c5:
Class 0 (High Stress):

Precision: 0.00 (None of the predicted high stress instances were correct)
Recall: 0.00 (None of the actual high stress instances were predicted correctly)
F1-Score: 0.00 (No balance between precision and recall as both are zero)
Support: 3 (There are 3 instances of high stress in the validation set)
Class 1 (Low Stress):

Precision: 0.69 (69% of the instances predicted as low stress were correct)
Recall: 0.79 (79% of the actual low stress instances were correctly identified)
F1-Score: 0.73 (A balance between precision and recall)
Support: 28 (There are 28 instances of low stress in the validation set)
Class 2 (Medium Stress):

Precision: 0.25 (25% of the instances predicted as medium stress were correct)
Recall: 0.22 (22% of the actual medium stress instances were correctly identified)
F1-Score: 0.24 (A balance between precision and recall)
Support: 9 (There are 9 instances of medium stress in the validation set)
Accuracy:

0.60 (60% of the instances were correctly classified)
Macro Average:

Precision: 0.31 (The unweighted average precision for all classes)
Recall: 0.34 (The unweighted average recall for all classes)
F1-Score: 0.32 (The unweighted average F1-score for all classes)
Weighted Average:

Precision: 0.54 (The average precision for all classes, weighted by support)
Recall: 0.60 (The average recall for all classes, weighted by support)
F1-Score: 0.57 (The average F1-score for all classes, weighted by support)
Cross-Validation Scores
Cross-validation scores:

These scores represent the performance of the classifier across different splits of the training data.
The array [0.5, 0.51923077, 0.55769231, 0.62745098, 0.37254902] shows the accuracy scores for each fold in a 5-fold cross-validation.
Average cross-validation score:

The average of the cross-validation scores, which provides an estimate of the model's performance on unseen data.
For Stress Level c5: 0.5153846153846154 (approximately 51.5%)
Summary
The report helps you understand how well your model performs in distinguishing between different classes, as well as identifying areas where the model may need improvement, especially for underrepresented classes like High Stress (class 0) in this case. If you need further assistance or have specific questions, feel free to ask
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score

# Load your dataset (uncomment and modify this line to load your dataset)
# df_omnis = pd.read_csv('your_dataset.csv')

# Define features and targets for all surveys
all_features = []
all_classification_targets = []
all_regression_targets = []

for i in range(1, 7):
    feature_set = [
        f'% Present 30 before Date c{i}', f'30 day average pre c{i}', f'7 day average pre c{i}',
        f'7 max - min pre c{i}', f'days increasing pre c{i}', f'30 max - min pre c{i}',
        f'3 max - min pre c{i}', f'ratio above below 30 c{i}', f'ratio above below 7 c{i}',
        f'3 day average pre c{i}', f'9 day average pre c{i}', f'days decreasing pre c{i}',
        f'avg Difference 7 days pre c{i}', f'Day before c{i}', f'avg Difference 3 days pre c{i}'
    ]
    features = df_omnis[['% All Data'] + feature_set]
    classification_target = df_omnis[f'Stress Level c{i}']
    regression_target = df_omnis[f'PSS Score at c{i}']

    all_features.append(features)
    all_classification_targets.append(classification_target)
    all_regression_targets.append(regression_target)

# Concatenate all data
combined_features = pd.concat(all_features, axis=0)
combined_classification_targets = pd.concat(all_classification_targets, axis=0)
combined_regression_targets = pd.concat(all_regression_targets, axis=0)

# Verify the shape of the combined data
print(f'Combined features shape: {combined_features.shape}')
print(f'Combined classification targets shape: {combined_classification_targets.shape}')
print(f'Combined regression targets shape: {combined_regression_targets.shape}')

# Handle missing values in combined data
feature_imputer = SimpleImputer(strategy='mean')
combined_features = feature_imputer.fit_transform(combined_features)

# Handle missing values in regression targets
target_imputer = SimpleImputer(strategy='mean')
combined_regression_targets = target_imputer.fit_transform(combined_regression_targets.values.reshape(-1, 1)).flatten()

# Standardize the features
scaler = StandardScaler()
combined_features = scaler.fit_transform(combined_features)

# Encode the classification targets
label_encoder = LabelEncoder()
combined_classification_targets = label_encoder.fit_transform(combined_classification_targets)

# Split data into training and validation sets
train_features, val_features, train_classification_targets, val_classification_targets, train_regression_targets, val_regression_targets = train_test_split(
    combined_features, combined_classification_targets, combined_regression_targets, test_size=0.2, random_state=42
)

# Train and evaluate the classification model
classifier = RandomForestClassifier()
classifier.fit(train_features, train_classification_targets)

val_predictions_classification = classifier.predict(val_features)
print(f"Classification Report:")
print(classification_report(val_classification_targets, val_predictions_classification))

cv_scores = cross_val_score(classifier, train_features, train_classification_targets, cv=5)
print(f"Cross-validation scores: {cv_scores}")
print(f"Average cross-validation score: {cv_scores.mean()}")

# Train and evaluate the regression model
regressor = RandomForestRegressor()
regressor.fit(train_features, train_regression_targets)

val_predictions_regression = regressor.predict(val_features)
mse = mean_squared_error(val_regression_targets, val_predictions_regression)
print(f'Mean Squared Error: {mse}')

"""Combined features shape: (1788, 91)

There are 1788 samples and 91 features in the combined dataset.
Combined classification targets shape: (1788,)

There are 1788 classification targets, one for each sample.
Combined regression targets shape: (1788,)

There are 1788 regression targets, one for each sample.
Classification Report
The classification report provides detailed metrics about the performance of your classification model.

Per-Class Metrics
Class 0:

Precision: 0.39 (39% of the instances predicted as class 0 were correct)
Recall: 0.32 (32% of the actual class 0 instances were correctly identified)
F1-Score: 0.35 (Harmonic mean of precision and recall for class 0)
Support: 75 (There are 75 instances of class 0 in the validation set)
Class 1:

Precision: 0.57 (57% of the instances predicted as class 1 were correct)
Recall: 0.72 (72% of the actual class 1 instances were correctly identified)
F1-Score: 0.63 (Harmonic mean of precision and recall for class 1)
Support: 157 (There are 157 instances of class 1 in the validation set)
Class 2:

Precision: 0.22 (22% of the instances predicted as class 2 were correct)
Recall: 0.15 (15% of the actual class 2 instances were correctly identified)
F1-Score: 0.18 (Harmonic mean of precision and recall for class 2)
Support: 88 (There are 88 instances of class 2 in the validation set)
Class 3:

Precision: 0.97 (97% of the instances predicted as class 3 were correct)
Recall: 1.00 (100% of the actual class 3 instances were correctly identified)
F1-Score: 0.99 (Harmonic mean of precision and recall for class 3)
Support: 38 (There are 38 instances of class 3 in the validation set)
Overall Metrics
Accuracy: 0.53

53% of the instances were correctly classified.
Macro Average:

Precision: 0.54 (Unweighted average precision for all classes)
Recall: 0.55 (Unweighted average recall for all classes)
F1-Score: 0.54 (Unweighted average F1-score for all classes)
Weighted Average:

Precision: 0.49 (Average precision for all classes, weighted by support)
Recall: 0.53 (Average recall for all classes, weighted by support)
F1-Score: 0.50 (Average F1-score for all classes, weighted by support)
Cross-Validation Scores
Cross-validation scores: [0.4965035, 0.53846154, 0.53146853, 0.58391608, 0.52097902]

These scores represent the accuracy of the classifier across different splits of the training data.
Each value corresponds to the accuracy for a specific fold in a 5-fold cross-validation.
Average cross-validation score: 0.5342657342657342 (approximately 53.4%)

The average of the cross-validation scores, providing an estimate of the model's performance on unseen data.
Mean Squared Error (MSE)
Mean Squared Error: 47.47788792564445
The average squared difference between the predicted and actual values for the regression task.
A lower MSE indicates that the predictions are closer to the actual values. Since the range of PSS scores typically is 0-40, an MSE of 47.48 indicates a significant average deviation between predicted and actual values.
Summary
Classification Report: Shows the performance of the classification model for each class and overall metrics.

Class 3 has very high precision and recall, indicating good performance for that class.
Class 2 has low precision and recall, indicating poor performance for that class.
The overall accuracy is 53%, indicating that the model correctly classifies about half of the instances.
Cross-Validation Scores: Indicate the stability of the model's performance across different data splits.

The average cross-validation score is 53.4%, similar to the validation accuracy.
Mean Squared Error: Provides an indication of the model's performance for the regression task.

An MSE of 47.48 suggests that there is a significant error in the regression predictions, given that the PSS scores range from 0 to 40.
These metrics provide a comprehensive view of the model's performance, highlighting areas of strength and weakness. If you have any specific questions or need further analysis, feel free to ask!








"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Assuming df_omnis is already loaded
# Define the classification target columns
Classification_targets = [f'Stress Level c{i}' for i in range(1, 7)]

# Print the mapping of numerical labels to original string values for each column
for column in Classification_targets:
    label_encoder = LabelEncoder()
    label_encoder.fit(df_omnis[column])
    print(f"Mapping for {column}:")
    for i, item in enumerate(label_encoder.classes_):
        print(f"Class {i}: {item}")

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score

# Load your dataset (uncomment and modify this line to load your dataset)
# df_omnis = pd.read_csv('your_dataset.csv')

# Define features and targets for all surveys
all_features = []
all_classification_targets = []
all_regression_targets = []

for i in range(1, 7):
    # Filter data points where '% Present 30 before Date c{i}' is 40% or more
    mask = df_omnis[f'% Present 30 before Date c{i}'] >= 40
    feature_set = [
        f'% Present 30 before Date c{i}', f'30 day average pre c{i}', f'7 day average pre c{i}',
        f'7 max - min pre c{i}', f'days increasing pre c{i}', f'30 max - min pre c{i}',
        f'3 max - min pre c{i}', f'ratio above below 30 c{i}', f'ratio above below 7 c{i}',
        f'3 day average pre c{i}', f'9 day average pre c{i}', f'days decreasing pre c{i}',
        f'avg Difference 7 days pre c{i}', f'Day before c{i}', f'avg Difference 3 days pre c{i}'
    ]
    features = df_omnis.loc[mask, ['% All Data'] + feature_set]
    classification_target = df_omnis.loc[mask, f'Stress Level c{i}']
    regression_target = df_omnis.loc[mask, f'PSS Score at c{i}']

    all_features.append(features)
    all_classification_targets.append(classification_target)
    all_regression_targets.append(regression_target)

# Concatenate all data
combined_features = pd.concat(all_features, axis=0)
combined_classification_targets = pd.concat(all_classification_targets, axis=0)
combined_regression_targets = pd.concat(all_regression_targets, axis=0)

# Verify the shape of the combined data
print(f'Combined features shape: {combined_features.shape}')
print(f'Combined classification targets shape: {combined_classification_targets.shape}')
print(f'Combined regression targets shape: {combined_regression_targets.shape}')

# Handle missing values in combined data
feature_imputer = SimpleImputer(strategy='mean')
combined_features = feature_imputer.fit_transform(combined_features)

# Handle missing values in regression targets
target_imputer = SimpleImputer(strategy='mean')
combined_regression_targets = target_imputer.fit_transform(combined_regression_targets.values.reshape(-1, 1)).flatten()

# Standardize the features
scaler = StandardScaler()
combined_features = scaler.fit_transform(combined_features)

# Encode the classification targets
label_encoder = LabelEncoder()
combined_classification_targets = label_encoder.fit_transform(combined_classification_targets)

# Split data into training and validation sets
train_features, val_features, train_classification_targets, val_classification_targets, train_regression_targets, val_regression_targets = train_test_split(
    combined_features, combined_classification_targets, combined_regression_targets, test_size=0.2, random_state=42
)

# Train and evaluate the classification model
classifier = RandomForestClassifier()
classifier.fit(train_features, train_classification_targets)

val_predictions_classification = classifier.predict(val_features)
print(f"Classification Report:")
print(classification_report(val_classification_targets, val_predictions_classification))

cv_scores = cross_val_score(classifier, train_features, train_classification_targets, cv=5)
print(f"Cross-validation scores: {cv_scores}")
print(f"Average cross-validation score: {cv_scores.mean()}")

# Train and evaluate the regression model
regressor = RandomForestRegressor()
regressor.fit(train_features, train_regression_targets)

val_predictions_regression = regressor.predict(val_features)
mse = mean_squared_error(val_regression_targets, val_predictions_regression)
print(f'Mean Squared Error: {mse}')

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score

# Load your dataset (uncomment and modify this line to load your dataset)
# df_omnis = pd.read_csv('your_dataset.csv')

# Define features and targets for all surveys
all_features = []
all_classification_targets = []
all_regression_targets = []

for i in range(1, 7):
    feature_set = [
        f'7 max - min pre c{i}', f'days increasing pre c{i}', f'30 max - min pre c{i}',
        f'3 max - min pre c{i}', f'ratio above below 30 c{i}', f'ratio above below 7 c{i}',
        f'days decreasing pre c{i}', f'avg Difference 7 days pre c{i}',
        f'avg Difference 3 days pre c{i}'
    ]
    features = df_omnis[['% All Data'] + feature_set]
    classification_target = df_omnis[f'Stress Level c{i}']
    regression_target = df_omnis[f'PSS Score at c{i}']

    all_features.append(features)
    all_classification_targets.append(classification_target)
    all_regression_targets.append(regression_target)

# Concatenate all data
combined_features = pd.concat(all_features, axis=0)
combined_classification_targets = pd.concat(all_classification_targets, axis=0)
combined_regression_targets = pd.concat(all_regression_targets, axis=0)

# Verify the shape of the combined data
print(f'Combined features shape: {combined_features.shape}')
print(f'Combined classification targets shape: {combined_classification_targets.shape}')
print(f'Combined regression targets shape: {combined_regression_targets.shape}')

# Handle missing values in combined data
feature_imputer = SimpleImputer(strategy='mean')
combined_features = feature_imputer.fit_transform(combined_features)

# Handle missing values in regression targets
target_imputer = SimpleImputer(strategy='mean')
combined_regression_targets = target_imputer.fit_transform(combined_regression_targets.values.reshape(-1, 1)).flatten()

# Standardize the features
scaler = StandardScaler()
combined_features = scaler.fit_transform(combined_features)

# Encode the classification targets
label_encoder = LabelEncoder()
combined_classification_targets = label_encoder.fit_transform(combined_classification_targets)

# Split data into training and validation sets
train_features, val_features, train_classification_targets, val_classification_targets, train_regression_targets, val_regression_targets = train_test_split(
    combined_features, combined_classification_targets, combined_regression_targets, test_size=0.2, random_state=42
)

# Train and evaluate the classification model
classifier = RandomForestClassifier()
classifier.fit(train_features, train_classification_targets)

val_predictions_classification = classifier.predict(val_features)
print(f"Classification Report:")
print(classification_report(val_classification_targets, val_predictions_classification))

cv_scores = cross_val_score(classifier, train_features, train_classification_targets, cv=5)
print(f"Cross-validation scores: {cv_scores}")
print(f"Average cross-validation score: {cv_scores.mean()}")

# Train and evaluate the regression model
regressor = RandomForestRegressor()
regressor.fit(train_features, train_regression_targets)

val_predictions_regression = regressor.predict(val_features)
mse = mean_squared_error(val_regression_targets, val_predictions_regression)
print(f'Mean Squared Error: {mse}')

'''
Simple Machine Learning
'''
def plot_stress_levels(pre_checkpoint_month, df_omnis, days_to_output=7, total_data_threshold=40, pre_survey_threshold=50):
    # Initialize lists to hold the specified number of day values for high and low stress groups
    high_days = []
    low_days = []

    # Print the dates column for verification
    print(pre_checkpoint_month['DTUW'])

    # Iterate through each row in df_omnis
    for idx, row in df_omnis.iterrows():
        identifier = row['Global_Deidentified']
        df = pre_checkpoint_month[identifier]
        date_dict = pre_checkpoint_month[identifier + 'c_dates']
        total_present = row['% All Data']

        if total_present > total_data_threshold:  # Check if the participant has more than the specified percentage of their total data present
            for i in range(1, 7):  # Loop through c1 to c6
                innerkey = f'c{i}'
                stressKey = 'Stress Level' + f' c{i}'
                stressState = row[stressKey]
                present_pre_survey = row['% Present 30 before Date ' + innerkey]

                # Check if innerkey exists in date_dict and present_pre_survey is more than the specified threshold
                if innerkey in date_dict and present_pre_survey > pre_survey_threshold:
                    # Extract the days prior to each checkpoint
                    dates_range = date_dict[innerkey]
                    days = df.loc[df['dates'].between(dates_range[0], dates_range[1])]

                    if not days.empty:
                        # Ensure days_to_output is not larger than the number of available days
                        num_days_available = len(days)
                        num_days_to_extract = min(days_to_output, num_days_available)

                        # Get the specified number of days of data before the survey
                        day_values = days.tail(num_days_to_extract).iloc[:, 1:].values.flatten().tolist()  # Assuming the first column is 'dates' and we need the rest

                        if stressState == 'Low Stress':
                            low_days.extend(day_values)
                        elif stressState == 'High Stress':
                            high_days.extend(day_values)

    # Convert lists to a format suitable for boxplot
    high_days = [value for value in high_days if not pd.isna(value)]
    low_days = [value for value in low_days if not pd.isna(value)]

    # Calculate statistics
    high_mean = np.mean(high_days)
    low_mean = np.mean(low_days)
    high_median = np.median(high_days)
    low_median = np.median(low_days)
    high_std = np.std(high_days)
    low_std = np.std(low_days)

    # Print statistics
    print("High Stress Group Statistics:")
    print(f"Mean: {high_mean}")
    print(f"Median: {high_median}")
    print(f"Standard Deviation: {high_std}")
    print("\nLow Stress Group Statistics:")
    print(f"Mean: {low_mean}")
    print(f"Median: {low_median}")
    print(f"Standard Deviation: {low_std}")

    # Create the box plot with enhanced styling
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=[high_days, low_days], palette="Set3")
    plt.xticks([0, 1], ['High Stress', 'Low Stress'])
    plt.title(f'Box plot of High Stress vs Low Stress\n(Days: Last {days_to_output}, Total Data Threshold: {total_data_threshold}%, Pre-Survey Threshold: {pre_survey_threshold}%)')
    plt.ylabel('Values')

    # Add statistics to the plot
    plt.text(0, high_mean, f'Mean: {high_mean:.2f}\nMedian: {high_median:.2f}\nStd: {high_std:.2f}', horizontalalignment='center', size='medium', color='black', weight='semibold')
    plt.text(1, low_mean, f'Mean: {low_mean:.2f}\nMedian: {low_median:.2f}\nStd: {low_std:.2f}', horizontalalignment='center', size='medium', color='black', weight='semibold')

    plt.show()

# Example usage:
for val in [1,3,7,10,15,30]:
  for tup in [(0,0),(40,50)]:
    plot_stress_levels(pre_checkpoint_month, df_omnis, days_to_output=val, total_data_threshold=tup[0], pre_survey_threshold=tup[1])

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score

def get_7_days_features(df, pre_checkpoint_month, days_to_output=7):
    all_features = []
    all_classification_targets = []
    all_regression_targets = []

    for i in range(1, 7):
        for idx, row in df.iterrows():
            identifier = row['Global_Deidentified']
            if identifier + 'c_dates' in pre_checkpoint_month:
                date_dict = pre_checkpoint_month[identifier + 'c_dates']
                innerkey = f'c{i}'
                stressKey = 'Stress Level' + f' c{i}'
                regression_target_key = f'PSS Score at c{i}'

                if innerkey in date_dict:
                    dates_range = date_dict[innerkey]
                    if identifier in pre_checkpoint_month:
                        days = pre_checkpoint_month[identifier].loc[pre_checkpoint_month[identifier]['dates'].between(dates_range[0], dates_range[1])]
                        days = days.tail(days_to_output)[innerkey].values  # Extract the specific column corresponding to the innerkey

                        # Fill missing values
                        for j in range(len(days)):
                            if np.isnan(days[j]):
                                if j > 0:
                                    days[j] = days[j - 1]
                                else:
                                    days[j] = np.nanmean(days)

                        # Ensure the feature vector has the correct length
                        if len(days) < days_to_output:
                            days = np.pad(days, (0, days_to_output - len(days)), 'constant', constant_values=np.nanmean(days))

                        all_features.append(days)
                        all_classification_targets.append(row[stressKey])
                        all_regression_targets.append(row[regression_target_key])

    return np.array(all_features), np.array(all_classification_targets), np.array(all_regression_targets)

# Get features and targets
combined_features, combined_classification_targets, combined_regression_targets = get_7_days_features(df_omnis, pre_checkpoint_month, 7)

# Verify the shape of the combined data
print(f'Combined features shape: {combined_features.shape}')
print(f'Combined classification targets shape: {combined_classification_targets.shape}')
print(f'Combined regression targets shape: {combined_regression_targets.shape}')

# Handle missing values in the features
feature_imputer = SimpleImputer(strategy='mean')
combined_features = feature_imputer.fit_transform(combined_features)

# Handle missing values in regression targets
target_imputer = SimpleImputer(strategy='mean')
combined_regression_targets = target_imputer.fit_transform(combined_regression_targets.reshape(-1, 1)).flatten()

# Standardize the features
scaler = StandardScaler()
combined_features = scaler.fit_transform(combined_features)

# Encode the classification targets
label_encoder = LabelEncoder()
combined_classification_targets = label_encoder.fit_transform(combined_classification_targets)

# Split data into training and validation sets
train_features, val_features, train_classification_targets, val_classification_targets, train_regression_targets, val_regression_targets = train_test_split(
    combined_features, combined_classification_targets, combined_regression_targets, test_size=0.2, random_state=42
)

# Train and evaluate the classification model
classifier = RandomForestClassifier()
classifier.fit(train_features, train_classification_targets)

val_predictions_classification = classifier.predict(val_features)
print(f"Classification Report:")
print(classification_report(val_classification_targets, val_predictions_classification))

cv_scores = cross_val_score(classifier, train_features, train_classification_targets, cv=5)
print(f"Cross-validation scores: {cv_scores}")
print(f"Average cross-validation score: {cv_scores.mean()}")

# Train and evaluate the regression model
regressor = RandomForestRegressor()
regressor.fit(train_features, train_regression_targets)

val_predictions_regression = regressor.predict(val_features)
mse = mean_squared_error(val_regression_targets, val_predictions_regression)
print(f'Mean Squared Error: {mse}')

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score

def get_n_days_features(df, pre_checkpoint_month, days_to_output=7):
    all_features = []
    all_classification_targets = []
    all_regression_targets = []

    for i in range(1, 7):
        for idx, row in df.iterrows():
            identifier = row['Global_Deidentified']
            if identifier + 'c_dates' in pre_checkpoint_month:
                date_dict = pre_checkpoint_month[identifier + 'c_dates']
                innerkey = f'c{i}'
                stressKey = 'Stress Level' + f' c{i}'
                regression_target_key = f'PSS Score at c{i}'

                if innerkey in date_dict:
                    dates_range = date_dict[innerkey]
                    if identifier in pre_checkpoint_month:
                        days = pre_checkpoint_month[identifier].loc[pre_checkpoint_month[identifier]['dates'].between(dates_range[0], dates_range[1])]
                        days = days.tail(days_to_output)[innerkey].values  # Extract the specific column corresponding to the innerkey

                        # Fill missing values
                        for j in range(len(days)):
                            if np.isnan(days[j]):
                                if j > 0:
                                    days[j] = days[j - 1]
                                else:
                                    days[j] = np.nanmean(days)

                        # Ensure the feature vector has the correct length
                        if len(days) < days_to_output:
                            days = np.pad(days, (0, days_to_output - len(days)), 'constant', constant_values=np.nanmean(days))

                        all_features.append(days)
                        all_classification_targets.append(row[stressKey])
                        all_regression_targets.append(row[regression_target_key])

    return np.array(all_features), np.array(all_classification_targets), np.array(all_regression_targets)

def run_ml_for_day_ranges(df_omnis, pre_checkpoint_month, day_ranges):
    for days_to_output in day_ranges:
        print(f"\nRunning machine learning for {days_to_output} days before the survey...\n")

        # Get features and targets
        combined_features, combined_classification_targets, combined_regression_targets = get_n_days_features(df_omnis, pre_checkpoint_month, days_to_output)

        # Verify the shape of the combined data
        print(f'Combined features shape: {combined_features.shape}')
        print(f'Combined classification targets shape: {combined_classification_targets.shape}')
        print(f'Combined regression targets shape: {combined_regression_targets.shape}')

        # Handle missing values in the features
        feature_imputer = SimpleImputer(strategy='mean')
        combined_features = feature_imputer.fit_transform(combined_features)

        # Handle missing values in regression targets
        target_imputer = SimpleImputer(strategy='mean')
        combined_regression_targets = target_imputer.fit_transform(combined_regression_targets.reshape(-1, 1)).flatten()

        # Standardize the features
        scaler = StandardScaler()
        combined_features = scaler.fit_transform(combined_features)

        # Encode the classification targets
        label_encoder = LabelEncoder()
        combined_classification_targets = label_encoder.fit_transform(combined_classification_targets)
        label_names = label_encoder.classes_

        # Split data into training and validation sets
        train_features, val_features, train_classification_targets, val_classification_targets, train_regression_targets, val_regression_targets = train_test_split(
            combined_features, combined_classification_targets, combined_regression_targets, test_size=0.2, random_state=42
        )

        # Train and evaluate the classification model
        classifier = RandomForestClassifier()
        classifier.fit(train_features, train_classification_targets)

        val_predictions_classification = classifier.predict(val_features)
        print(f"Classification Report for {days_to_output} days:")
        print(classification_report(val_classification_targets, val_predictions_classification, target_names=label_names))

        cv_scores = cross_val_score(classifier, train_features, train_classification_targets, cv=5)
        print(f"Cross-validation scores for {days_to_output} days: {cv_scores}")
        print(f"Average cross-validation score for {days_to_output} days: {cv_scores.mean()}")

        # Train and evaluate the regression model
        regressor = RandomForestRegressor()
        regressor.fit(train_features, train_regression_targets)

        val_predictions_regression = regressor.predict(val_features)
        mse = mean_squared_error(val_regression_targets, val_predictions_regression)
        print(f'Mean Squared Error for {days_to_output} days: {mse}')

# Example usage
day_ranges = [1, 3, 7, 10, 15, 30]
run_ml_for_day_ranges(df_omnis, pre_checkpoint_month, day_ranges)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.experimental import enable_hist_gradient_boosting
from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor
from sklearn.metrics import classification_report, mean_squared_error
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, cross_val_score

def get_7_days_features(df, pre_checkpoint_month, days_to_output=7):
    all_features = []
    all_classification_targets = []
    all_regression_targets = []

    for i in range(1, 7):
        for idx, row in df.iterrows():
            identifier = row['Global_Deidentified']
            if identifier + 'c_dates' in pre_checkpoint_month:
                date_dict = pre_checkpoint_month[identifier + 'c_dates']
                innerkey = f'c{i}'
                stressKey = 'Stress Level' + f' c{i}'
                regression_target_key = f'PSS Score at c{i}'

                if innerkey in date_dict:
                    dates_range = date_dict[innerkey]
                    if identifier in pre_checkpoint_month:
                        days = pre_checkpoint_month[identifier].loc[pre_checkpoint_month[identifier]['dates'].between(dates_range[0], dates_range[1])]
                        days = days.tail(days_to_output)[innerkey].values  # Extract the specific column corresponding to the innerkey

                        # Fill missing values
                        for j in range(len(days)):
                            if np.isnan(days[j]):
                                if j > 0:
                                    days[j] = days[j - 1]
                                else:
                                    days[j] = np.nanmean(days)

                        # Ensure the feature vector has the correct length
                        if len(days) < days_to_output:
                            days = np.pad(days, (0, days_to_output - len(days)), 'constant', constant_values=np.nanmean(days))

                        all_features.append(days)
                        all_classification_targets.append(row[stressKey])
                        all_regression_targets.append(row[regression_target_key])

    return np.array(all_features), np.array(all_classification_targets), np.array(all_regression_targets)

# Get 7 days features and targets
for val in [1,3,7,10,15,30]:
  days_features, days_classification_targets, days_regression_targets = get_7_days_features(df_omnis, pre_checkpoint_month, val)

  # Define engineered features and targets
  all_engineered_features = []
  all_engineered_classification_targets = []
  all_engineered_regression_targets = []

  for i in range(1, 7):
      feature_set = [
          f'7 max - min pre c{i}', f'days increasing pre c{i}', f'30 max - min pre c{i}',
          f'3 max - min pre c{i}', f'ratio above below 30 c{i}', f'ratio above below 7 c{i}',
          f'days decreasing pre c{i}', f'avg Difference 7 days pre c{i}',
          f'avg Difference 3 days pre c{i}'
      ]
      features = df_omnis[['% All Data'] + feature_set]
      classification_target = df_omnis[f'Stress Level c{i}']
      regression_target = df_omnis[f'PSS Score at c{i}']

      all_engineered_features.append(features)
      all_engineered_classification_targets.append(classification_target)
      all_engineered_regression_targets.append(regression_target)

  # Concatenate all engineered data
  combined_engineered_features = pd.concat(all_engineered_features, axis=0)
  combined_engineered_classification_targets = pd.concat(all_engineered_classification_targets, axis=0)
  combined_engineered_regression_targets = pd.concat(all_engineered_regression_targets, axis=0)

  # Ensure consistent lengths by trimming the longer array to the length of the shortest one
  min_length = min(len(days_features), len(combined_engineered_features), len(days_classification_targets), len(days_regression_targets))
  days_features = days_features[:min_length]
  combined_engineered_features = combined_engineered_features[:min_length]
  days_classification_targets = days_classification_targets[:min_length]
  days_regression_targets = days_regression_targets[:min_length]

  # Handle missing values in engineered features
  feature_imputer = SimpleImputer(strategy='mean')
  combined_engineered_features = feature_imputer.fit_transform(combined_engineered_features)

  # Combine days features and engineered features
  combined_features = np.hstack((days_features, combined_engineered_features))

  # Handle missing values in regression targets
  target_imputer = SimpleImputer(strategy='mean')
  combined_regression_targets = target_imputer.fit_transform(days_regression_targets.reshape(-1, 1)).flatten()

  # Standardize the features
  scaler = StandardScaler()
  combined_features = scaler.fit_transform(combined_features)

  # Encode the classification targets
  label_encoder = LabelEncoder()
  combined_classification_targets = label_encoder.fit_transform(days_classification_targets)

  # Split data into training and validation sets
  train_features, val_features, train_classification_targets, val_classification_targets, train_regression_targets, val_regression_targets = train_test_split(
      combined_features, combined_classification_targets, combined_regression_targets, test_size=0.2, random_state=42
  )

  # Train and evaluate the classification model
  classifier = HistGradientBoostingClassifier()
  classifier.fit(train_features, train_classification_targets)
  print(f"\nRunning machine learning for {val} days before the survey...\n")
  print(f"Classification Report for {val} days as well as engineered features:")

  val_predictions_classification = classifier.predict(val_features)
  print(f"Classification Report:")
  print(classification_report(val_classification_targets, val_predictions_classification))

  cv_scores = cross_val_score(classifier, train_features, train_classification_targets, cv=5)
  print(f"Cross-validation scores: {cv_scores}")
  print(f"Average cross-validation score: {cv_scores.mean()}")

  # Train and evaluate the regression model
  regressor = HistGradientBoostingRegressor()
  regressor.fit(train_features, train_regression_targets)

  val_predictions_regression = regressor.predict(val_features)
  mse = mean_squared_error(val_regression_targets, val_predictions_regression)
  print(f'Mean Squared Error: {mse}')
